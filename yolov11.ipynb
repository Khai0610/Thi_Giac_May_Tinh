{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe943a60",
   "metadata": {
    "papermill": {
     "duration": 0.00484,
     "end_time": "2025-10-13T16:33:01.853395",
     "exception": false,
     "start_time": "2025-10-13T16:33:01.848555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# AICity Challenge 2025 â€” Track 4 (FishEye)  \n",
    "## YOLO11 (Ultralytics) â€” Train on FishEye8K â†’ Inference on FishEye1Keval â†’ `submission.json`\n",
    "\n",
    "**What this notebook does**\n",
    "- Installs latest Ultralytics (YOLO **v11** family).\n",
    "- Converts **FishEye8K** to YOLO format if itâ€™s in COCO (auto-detect).\n",
    "- Trains YOLO on FishEye8K.\n",
    "- Runs inference on **FishEye1Keval (1000 imgs)** and writes `submission.json` in **exact format** required.\n",
    "- Measures endâ€‘toâ€‘end **FPS** for the 1000 images and reports `FPS` and `NormFPS` (MaxFPS=25).\n",
    "\n",
    "> **Classes / IDs (fixed by track):** Bus=0, Bike=1, Car=2, Pedestrian=3, Truck=4  \n",
    "> **Image ID rule (from organizers):** `image_id = int(f\"{cameraIndex}{sceneIndex}{frame}\")` with scene map `{'M':0,'A':1,'E':2,'N':3}`.\n",
    "\n",
    "> **Datasets (edit paths below to match your Kaggle Inputs):**  \n",
    "> `FISHEYE8K_ROOT = /kaggle/input/fisheye8k`  \n",
    "> `FISHEYE1K_ROOT = /kaggle/input/fisheye1keval`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d73837e6-9bc7-4f87-b3ad-e38bf3ad0b0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T16:33:01.862751Z",
     "iopub.status.busy": "2025-10-13T16:33:01.862342Z",
     "iopub.status.idle": "2025-10-13T16:35:01.698093Z",
     "shell.execute_reply": "2025-10-13T16:35:01.696292Z"
    },
    "papermill": {
     "duration": 119.8437,
     "end_time": "2025-10-13T16:35:01.701147",
     "exception": false,
     "start_time": "2025-10-13T16:33:01.857447",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\r\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\r\n",
      "mkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "mkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\r\n",
      "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\r\n",
      "datasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\r\n",
      "onnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "ydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "google-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\r\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\r\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\r\n",
      "google-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\r\n",
      "dopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "imbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "transformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\r\n",
      "plotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\r\n",
      "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\r\n",
      "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "mlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q \"ultralytics>=8.3.209\"\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,max_split_size_mb:64\"\n",
    "os.environ[\"NCCL_P2P_DISABLE\"] = \"1\"\n",
    "os.environ[\"NCCL_IB_DISABLE\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f2130ee-65e2-4b56-94f9-8f6e45e79dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T16:35:01.792957Z",
     "iopub.status.busy": "2025-10-13T16:35:01.792544Z",
     "iopub.status.idle": "2025-10-13T16:35:01.799416Z",
     "shell.execute_reply": "2025-10-13T16:35:01.798183Z"
    },
    "papermill": {
     "duration": 0.055366,
     "end_time": "2025-10-13T16:35:01.801495",
     "exception": false,
     "start_time": "2025-10-13T16:35:01.746129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "869e5f35-6c0d-47e9-b7f2-77b2a43b2c7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T16:35:01.892402Z",
     "iopub.status.busy": "2025-10-13T16:35:01.892010Z",
     "iopub.status.idle": "2025-10-13T16:35:07.767621Z",
     "shell.execute_reply": "2025-10-13T16:35:07.766040Z"
    },
    "papermill": {
     "duration": 5.923009,
     "end_time": "2025-10-13T16:35:07.769773",
     "exception": false,
     "start_time": "2025-10-13T16:35:01.846764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device_count: 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"device_count:\", torch.cuda.device_count())\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(i, torch.cuda.get_device_name(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd33c81d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T16:35:07.876212Z",
     "iopub.status.busy": "2025-10-13T16:35:07.875680Z",
     "iopub.status.idle": "2025-10-13T16:35:07.888497Z",
     "shell.execute_reply": "2025-10-13T16:35:07.886874Z"
    },
    "papermill": {
     "duration": 0.073171,
     "end_time": "2025-10-13T16:35:07.890403",
     "exception": false,
     "start_time": "2025-10-13T16:35:07.817232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FishEye8K root    : /kaggle/input/fisheye8k/Fisheye8K exists: True\n",
      "FishEye1Keval root: /kaggle/input/fisheye1k/Fisheye1K exists: False\n",
      "Workdir           : /kaggle/working/aicity2025_track4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ===============================\n",
    "# 1) ENV & PATHS (EDIT IF NEEDED)\n",
    "# ===============================\n",
    "import os, sys, json, time, glob, shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# Default Kaggle input paths (rename to match your datasets)\n",
    "FISHEYE8K_ROOT = Path(\"/kaggle/input/fisheye8k/Fisheye8K\")\n",
    "FISHEYE1K_ROOT = Path(\"/kaggle/input/fisheye1k/Fisheye1K\")\n",
    "\n",
    "WORKDIR = Path(\"/kaggle/working/aicity2025_track4\")\n",
    "WORKDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATASETS_DIR = WORKDIR / \"datasets\"\n",
    "DATASETS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUBMISSION_JSON = WORKDIR / \"submission.json\"\n",
    "METRICS_JSON    = WORKDIR / \"speed_metrics.json\"\n",
    "\n",
    "CLASS_NAMES = [\"Bus\",\"Bike\",\"Car\",\"Pedestrian\",\"Truck\"]\n",
    "CLASS_TO_ID = {n:i for i,n in enumerate(CLASS_NAMES)}\n",
    "\n",
    "print(\"FishEye8K root    :\", FISHEYE8K_ROOT, \"exists:\", FISHEYE8K_ROOT.exists())\n",
    "print(\"FishEye1Keval root:\", FISHEYE1K_ROOT, \"exists:\", FISHEYE1K_ROOT.exists())\n",
    "print(\"Workdir           :\", WORKDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "460e3a63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T16:35:07.979922Z",
     "iopub.status.busy": "2025-10-13T16:35:07.978867Z",
     "iopub.status.idle": "2025-10-13T16:35:08.642783Z",
     "shell.execute_reply": "2025-10-13T16:35:08.641158Z"
    },
    "papermill": {
     "duration": 0.711602,
     "end_time": "2025-10-13T16:35:08.644766",
     "exception": false,
     "start_time": "2025-10-13T16:35:07.933164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Ultralytics: 8.3.213 - Python: 3.11.13\n"
     ]
    }
   ],
   "source": [
    "import ultralytics, platform\n",
    "print(\"Ultralytics:\", ultralytics.__version__, \"- Python:\", platform.python_version())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c387709-c1d8-40dd-a7d5-873274d58ffb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T16:35:08.737882Z",
     "iopub.status.busy": "2025-10-13T16:35:08.737445Z",
     "iopub.status.idle": "2025-10-13T16:35:08.892847Z",
     "shell.execute_reply": "2025-10-13T16:35:08.891228Z"
    },
    "papermill": {
     "duration": 0.203818,
     "end_time": "2025-10-13T16:35:08.895496",
     "exception": false,
     "start_time": "2025-10-13T16:35:08.691678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvidia-smi: command not found\r\n",
      "torch: 2.6.0+cu124 | torch.cuda: 12.4 | is_available: False\n",
      "CUDA_VISIBLE_DEVICES: 0,1\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch, os, platform\n",
    "print(\"torch:\", torch.__version__,\n",
    "      \"| torch.cuda:\", torch.version.cuda,\n",
    "      \"| is_available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65bb319f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T16:35:08.991697Z",
     "iopub.status.busy": "2025-10-13T16:35:08.991220Z",
     "iopub.status.idle": "2025-10-13T16:35:09.003624Z",
     "shell.execute_reply": "2025-10-13T16:35:09.001576Z"
    },
    "papermill": {
     "duration": 0.066013,
     "end_time": "2025-10-13T16:35:09.006676",
     "exception": false,
     "start_time": "2025-10-13T16:35:08.940663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ======================================\n",
    "# 3) UTILS: conversion + image_id helper\n",
    "# ======================================\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "SCENE_LIST = ['M','A','E','N']\n",
    "\n",
    "def get_image_Id(img_name: str) -> int:\n",
    "    img_name = img_name.split('.png')[0]\n",
    "    cameraIndx = int(img_name.split('_')[0].replace('camera',''))\n",
    "    sceneIndx  = SCENE_LIST.index(img_name.split('_')[1])\n",
    "    frameIndx  = int(img_name.split('_')[2])\n",
    "    return int(f\"{cameraIndx}{sceneIndx}{frameIndx}\")\n",
    "\n",
    "def ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def find_first_existing(paths):\n",
    "    for p in paths:\n",
    "        if Path(p).exists(): return Path(p)\n",
    "    return None\n",
    "\n",
    "def coco_to_yolo_one_bbox(x, y, w, h, img_w, img_h):\n",
    "    cx = (x + w/2) / img_w\n",
    "    cy = (y + h/2) / img_h\n",
    "    return cx, cy, w/img_w, h/img_h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e9f691",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T16:35:09.129593Z",
     "iopub.status.busy": "2025-10-13T16:35:09.128806Z",
     "iopub.status.idle": "2025-10-13T16:41:20.570706Z",
     "shell.execute_reply": "2025-10-13T16:41:20.569391Z"
    },
    "papermill": {
     "duration": 371.506199,
     "end_time": "2025-10-13T16:41:20.572957",
     "exception": false,
     "start_time": "2025-10-13T16:35:09.066758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting COCO -> YOLO: train.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5288/5288 [04:19<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting COCO -> YOLO: test.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2712/2712 [01:50<00:00, 24.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data YAML: /kaggle/working/aicity2025_track4/datasets/fisheye8k_yolo/fisheye8k.yaml\n",
      "Train imgs: 5288\n",
      "Val imgs  : 2712\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================================================\n",
    "# 4) PREPARE FISHEYE8K in YOLO format for Ultralytics\n",
    "# =====================================================\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "TARGET_YOLO = DATASETS_DIR / \"fisheye8k_yolo\"\n",
    "IMG_TRAIN = TARGET_YOLO / \"images\" / \"train\"\n",
    "IMG_VAL   = TARGET_YOLO / \"images\" / \"val\"\n",
    "LBL_TRAIN = TARGET_YOLO / \"labels\" / \"train\"\n",
    "LBL_VAL   = TARGET_YOLO / \"labels\" / \"val\"\n",
    "for p in [IMG_TRAIN, IMG_VAL, LBL_TRAIN, LBL_VAL]: ensure_dir(p)\n",
    "\n",
    "def copy_all(src_glob, dst_dir: Path):\n",
    "    for s in glob.glob(str(src_glob)):\n",
    "        dst = dst_dir / Path(s).name\n",
    "        if not dst.exists(): shutil.copy2(s, dst)\n",
    "\n",
    "def convert_coco_split(images_dir: Path, coco_json_path: Path, yolo_img_dir: Path, yolo_lbl_dir: Path):\n",
    "    print(f\"Converting COCO -> YOLO:\", coco_json_path.name)\n",
    "    with open(coco_json_path,'r') as f:\n",
    "        coco = json.load(f)\n",
    "    img_dict = {img[\"id\"]: img for img in coco[\"images\"]}\n",
    "    anns_by_img = {}\n",
    "    for ann in coco[\"annotations\"]:\n",
    "        if ann.get(\"iscrowd\",0) == 1: continue\n",
    "        anns_by_img.setdefault(ann[\"image_id\"], []).append(ann)\n",
    "    # Category mapping by name (fallback: keep IDs)\n",
    "    cat_map = {}\n",
    "    if \"categories\" in coco:\n",
    "        for c in coco[\"categories\"]:\n",
    "            name = c[\"name\"]\n",
    "            cat_map[c[\"id\"]] = CLASS_TO_ID.get(name, c[\"id\"])\n",
    "    for img_id, info in tqdm(img_dict.items()):\n",
    "        fn = info[\"file_name\"]\n",
    "        src_img = images_dir / fn\n",
    "        if not src_img.exists():\n",
    "            # try nested common locations\n",
    "            cand = find_first_existing([images_dir/\"train\"/fn, images_dir/\"val\"/fn, images_dir/\"images\"/fn])\n",
    "            if cand is not None: src_img = cand\n",
    "        if not src_img.exists():\n",
    "            continue\n",
    "        dst_img = yolo_img_dir / Path(fn).name\n",
    "        if not dst_img.exists(): shutil.copy2(src_img, dst_img)\n",
    "        W = info.get(\"width\"); H = info.get(\"height\")\n",
    "        if W is None or H is None:\n",
    "            with Image.open(src_img) as im: W,H = im.size\n",
    "        lines = []\n",
    "        for ann in anns_by_img.get(img_id, []):\n",
    "            x,y,w,h = ann[\"bbox\"]\n",
    "            cx,cy,nw,nh = coco_to_yolo_one_bbox(x,y,w,h,W,H)\n",
    "            cat = cat_map.get(ann[\"category_id\"], ann[\"category_id\"])\n",
    "            lines.append(f\"{cat} {cx:.6f} {cy:.6f} {nw:.6f} {nh:.6f}\")\n",
    "        (yolo_lbl_dir / (Path(fn).stem + \".txt\")).write_text(\"\\n\".join(lines))\n",
    "\n",
    "# Heuristics: read COCO jsons if present\n",
    "train_json = FISHEYE8K_ROOT / \"train\" / \"train.json\"\n",
    "val_json   = FISHEYE8K_ROOT / \"test\"  / \"test.json\"\n",
    "\n",
    "images_train_root = FISHEYE8K_ROOT / \"train\" / \"images\"\n",
    "images_val_root   = FISHEYE8K_ROOT / \"test\"  / \"images\"\n",
    "\n",
    "if train_json and val_json:\n",
    "    convert_coco_split(images_train_root, train_json, IMG_TRAIN, LBL_TRAIN)\n",
    "    convert_coco_split(images_val_root, val_json,   IMG_VAL,   LBL_VAL)\n",
    "else:\n",
    "    # Already YOLO? Copy over standard tree\n",
    "    for sub in [\"train\",\"val\"]:\n",
    "        copy_all(images_root/f\"images/{sub}/*\", TARGET_YOLO/f\"images/{sub}\")\n",
    "        copy_all(images_root/f\"labels/{sub}/*\", TARGET_YOLO/f\"labels/{sub}\")\n",
    "\n",
    "# Write Ultralytics YAML\n",
    "yaml_text = f\"\"\"\n",
    "# FishEye8K data config for Ultralytics\n",
    "path: {TARGET_YOLO.as_posix()}\n",
    "train: images/train\n",
    "val: images/val\n",
    "names:\n",
    "  0: Bus\n",
    "  1: Bike\n",
    "  2: Car\n",
    "  3: Pedestrian\n",
    "  4: Truck\n",
    "\"\"\"\n",
    "(TARGET_YOLO / \"fisheye8k.yaml\").write_text(yaml_text)\n",
    "print(\"Data YAML:\", (TARGET_YOLO / \"fisheye8k.yaml\"))\n",
    "print(\"Train imgs:\", len(list(IMG_TRAIN.glob('*.png'))) + len(list(IMG_TRAIN.glob('*.jpg'))))\n",
    "print(\"Val imgs  :\", len(list(IMG_VAL.glob('*.png'))) + len(list(IMG_VAL.glob('*.jpg'))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31465031",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-13T16:41:20.989521Z",
     "iopub.status.busy": "2025-10-13T16:41:20.989165Z",
     "iopub.status.idle": "2025-10-13T16:41:23.609458Z",
     "shell.execute_reply": "2025-10-13T16:41:23.607268Z"
    },
    "papermill": {
     "duration": 2.846204,
     "end_time": "2025-10-13T16:41:23.612146",
     "exception": true,
     "start_time": "2025-10-13T16:41:20.765942",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo12l.pt to 'yolo12l.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 51.2MB 82.5MB/s 0.6s\n",
      "Ultralytics 8.3.213 ğŸš€ Python-3.11.13 torch-2.6.0+cu124 \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid CUDA 'device=0,1' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 0,1\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/522267238.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBASE_MODEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m results = model.train(\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDATA_YAML\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/models/yolo/detect/train.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0m_callbacks\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptional\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0mfunctions\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mexecuted\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbuild_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cfg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;31m# Update \"-1\" devices so post-training val does not repeat search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetenv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/utils/torch_utils.py\u001b[0m in \u001b[0;36mselect_device\u001b[0;34m(device, newline, verbose)\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             )\n\u001b[0;32m--> 199\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0;34mf\"Invalid CUDA 'device={device}' requested.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;34mf\" Use 'device=cpu' or pass valid CUDA device(s) if available,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid CUDA 'device=0,1' requested. Use 'device=cpu' or pass valid CUDA device(s) if available, i.e. 'device=0' or 'device=0,1,2,3' for Multi-GPU.\n\ntorch.cuda.is_available(): False\ntorch.cuda.device_count(): 0\nos.environ['CUDA_VISIBLE_DEVICES']: 0,1\nSee https://pytorch.org/get-started/locally/ for up-to-date torch install instructions if no CUDA devices are seen by torch.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==================================\n",
    "# 5) TRAIN â€” Ultralytics YOLO (v11)\n",
    "# ==================================\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True,max_split_size_mb:128\"\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "DATA_YAML = (DATASETS_DIR / \"fisheye8k_yolo\" / \"fisheye8k.yaml\").as_posix()\n",
    "\n",
    "BASE_MODEL = \"yolo12l.pt\"   # náº¿u váº«n trá»¥c tráº·c -> \"yolo12m.pt\"\n",
    "EPOCHS     = 150\n",
    "IMG_SIZE   = 704\n",
    "BATCH      = 12             # 2 GPU => 6/GPU\n",
    "NBS        = 48             # giáº£m tá»« 64 -> 48 Ä‘á»ƒ LR hiá»‡u dá»¥ng dá»‹u hÆ¡n\n",
    "\n",
    "model = YOLO(BASE_MODEL)\n",
    "results = model.train(\n",
    "    data=DATA_YAML,\n",
    "    epochs=EPOCHS,\n",
    "    imgsz=IMG_SIZE,\n",
    "    batch=BATCH,\n",
    "    nbs=NBS,\n",
    "    device=\"0,1\",\n",
    "    workers=2,\n",
    "\n",
    "    # á»”n Ä‘á»‹nh sá»‘ há»c & LR\n",
    "    amp=False,               # âœ… táº¯t FP16 Ä‘á»ƒ trÃ¡nh NaN sá»›m\n",
    "    optimizer=\"adamw\",       # âœ… adamw á»•n Ä‘á»‹nh hÆ¡n SGD Ä‘áº§u train\n",
    "    lr0=0.001,               # âœ… LR dá»‹u (cÃ³ thá»ƒ 0.0008â€“0.0015)\n",
    "    lrf=0.01,                # giá»¯ cuá»‘i ká»³ tháº¥p\n",
    "    warmup_epochs=5,         # warmup dÃ i hÆ¡n\n",
    "\n",
    "    # Giáº£m Ä‘á»™ â€œgáº¯tâ€ cá»§a augment giai Ä‘oáº¡n Ä‘áº§u\n",
    "    mosaic=0.3,              # 0.5 -> 0.3\n",
    "    scale=0.35,              # 0.5 -> 0.35\n",
    "    erasing=0.2,             # 0.4 -> 0.2\n",
    "    hsv_s=0.5, hsv_v=0.2,    # dá»‹u mÃ u/Ä‘á»™ sÃ¡ng\n",
    "\n",
    "    # TrÃ¡nh peak VRAM trong DDP\n",
    "    compile=False,\n",
    "    multi_scale=False,\n",
    "\n",
    "    cos_lr=True,\n",
    "    patience=25,\n",
    "    save_period=10,\n",
    "    cache=False,\n",
    ")\n",
    "\n",
    "# Locate best checkpoint\n",
    "save_dir = Path(results.save_dir) if hasattr(results, \"save_dir\") else Path(\"runs/detect/train\")\n",
    "best_pt = save_dir / \"weights\" / \"best.pt\"\n",
    "print(\"Best checkpoint:\", best_pt, \"exists:\", best_pt.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886d6c61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T18:38:06.229751Z",
     "iopub.status.busy": "2025-10-12T18:38:06.228989Z",
     "iopub.status.idle": "2025-10-12T18:39:53.500623Z",
     "shell.execute_reply": "2025-10-12T18:39:53.499414Z",
     "shell.execute_reply.started": "2025-10-12T18:38:06.229724Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# =======================\n",
    "# 6) (Optional) VALIDATE\n",
    "# =======================\n",
    "_ = model.val(data=DATA_YAML, imgsz=int(os.environ.get(\"AICITY_VAL_IMSIZE\", \"832\")),\n",
    "              device=0 if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c06d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T18:40:03.880807Z",
     "iopub.status.busy": "2025-10-12T18:40:03.879930Z",
     "iopub.status.idle": "2025-10-12T18:44:15.829101Z",
     "shell.execute_reply": "2025-10-12T18:44:15.828132Z",
     "shell.execute_reply.started": "2025-10-12T18:40:03.880780Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ========================================================\n",
    "# 7) INFERENCE on FishEye1Keval â€” create submission.json\n",
    "# ========================================================\n",
    "from pathlib import Path\n",
    "import time, json, torch, gc, os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Clear VRAM\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "best_pt = \"/kaggle/working/runs/detect/train/weights/best.pt\"\n",
    "FISHEYE1K_ROOT = Path(\"/kaggle/input/fisheye1k/Fisheye1K\")\n",
    "WORKDIR = Path(\"/kaggle/working/aicity2025_track4\")\n",
    "SUBMISSION_JSON = WORKDIR / \"submission.json\"\n",
    "METRICS_JSON    = WORKDIR / \"speed_metrics.json\"\n",
    "\n",
    "assert Path(best_pt).exists(), \"best.pt not found\"\n",
    "model = YOLO(best_pt)\n",
    "\n",
    "IMG_SIZE = 832   # nhá» hÆ¡n Ä‘á»ƒ trÃ¡nh OOM\n",
    "CONF_THRES = 0.05\n",
    "IOU_THRES  = 0.5\n",
    "MAX_DETS   = 300\n",
    "\n",
    "# Collect test images\n",
    "test_imgs = sorted([p for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\") for p in FISHEYE1K_ROOT.rglob(ext)])\n",
    "print(\"Test images:\", len(test_imgs))\n",
    "SCENE_LIST = ['M','A','E','N']\n",
    "def get_image_Id(img_name: str) -> int:\n",
    "    img_name = img_name.split('.png')[0]\n",
    "    cameraIndx = int(img_name.split('_')[0].replace('camera',''))\n",
    "    sceneIndx  = SCENE_LIST.index(img_name.split('_')[1])\n",
    "    frameIndx  = int(img_name.split('_')[2])\n",
    "    return int(f\"{cameraIndx}{sceneIndx}{frameIndx}\")\n",
    "    \n",
    "# Inference\n",
    "start = time.time()\n",
    "records = []\n",
    "chunk_size = 50   # nhá» Ä‘á»ƒ trÃ¡nh OOM\n",
    "for i in range(0, len(test_imgs), chunk_size):\n",
    "    subset = test_imgs[i:i+chunk_size]\n",
    "    pred_gen = model.predict(\n",
    "        source=[str(p) for p in subset],\n",
    "        imgsz=IMG_SIZE,\n",
    "        conf=CONF_THRES,\n",
    "        iou=IOU_THRES,\n",
    "        max_det=MAX_DETS,\n",
    "        device=0,\n",
    "        verbose=False,\n",
    "        stream=True,\n",
    "        batch=2,\n",
    "        augment=False\n",
    "    )\n",
    "    for img_path, res in zip(subset, pred_gen):\n",
    "        h, w = res.orig_shape[:2]\n",
    "        image_name = Path(img_path).name\n",
    "        image_id = get_image_Id(image_name)\n",
    "        if res.boxes is None or len(res.boxes) == 0:\n",
    "            continue\n",
    "        for b in res.boxes:\n",
    "            x1, y1, x2, y2 = b.xyxy[0].tolist()\n",
    "            x1 = max(0.0, min(float(x1), w-1))\n",
    "            y1 = max(0.0, min(float(y1), h-1))\n",
    "            bw = max(0.0, min(float(x2)-x1, w - x1))\n",
    "            bh = max(0.0, min(float(y2)-y1, h - y1))\n",
    "            cls_id = int(b.cls.item())\n",
    "            score  = float(b.conf.item())\n",
    "            rec = {\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": cls_id,\n",
    "                \"bbox\": [x1, y1, bw, bh],\n",
    "                \"score\": score\n",
    "            }\n",
    "            records.append(rec)\n",
    "\n",
    "elapsed = time.time() - start\n",
    "N = len(test_imgs)\n",
    "fps = N / elapsed\n",
    "norm_fps = min(fps, 25.0) / 25.0\n",
    "\n",
    "with open(SUBMISSION_JSON, \"w\") as f:\n",
    "    json.dump(records, f)\n",
    "with open(METRICS_JSON, \"w\") as f:\n",
    "    json.dump({\"N\": N, \"time_sec\": elapsed, \"FPS\": fps, \"NormFPS\": norm_fps}, f, indent=2)\n",
    "\n",
    "print(f\"Processed {N} images in {elapsed:.2f}s â†’ FPS={fps:.2f}, NormFPS={norm_fps:.3f}\")\n",
    "print(\"Sample entries:\", records[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6415c8f6-5ac5-4a1d-86dd-b3cd10176921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T18:37:43.489013Z",
     "iopub.status.busy": "2025-10-12T18:37:43.488734Z",
     "iopub.status.idle": "2025-10-12T18:37:44.575224Z",
     "shell.execute_reply": "2025-10-12T18:37:44.574117Z",
     "shell.execute_reply.started": "2025-10-12T18:37:43.488992Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 8) VIZ â€” Training curves\n",
    "# ===============================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Image as IPyImage\n",
    "\n",
    "# TÃ¬m thÆ° má»¥c run cá»§a láº§n train hiá»‡n táº¡i\n",
    "train_dir = Path(results.save_dir) if hasattr(results, \"save_dir\") else Path(\"runs/detect/train\")\n",
    "csv_path  = train_dir / \"results.csv\"\n",
    "png_path  = train_dir / \"results.png\"\n",
    "\n",
    "print(\"Train dir:\", train_dir)\n",
    "if csv_path.exists():\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # Váº½ cÃ¡c loss\n",
    "    for col in [c for c in df.columns if \"loss\" in c.lower()]:\n",
    "        plt.figure()\n",
    "        plt.plot(df[\"epoch\"], df[col])\n",
    "        plt.title(col)\n",
    "        plt.xlabel(\"epoch\"); plt.ylabel(col)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "    # Váº½ cÃ¡c metric (mAP, precision, recall, F1 náº¿u cÃ³)\n",
    "    metric_cols = [c for c in df.columns if (\"map\" in c.lower() or \"precision\" in c.lower() or \"recall\" in c.lower() or \"f1\" in c.lower())]\n",
    "    for col in metric_cols:\n",
    "        plt.figure()\n",
    "        plt.plot(df[\"epoch\"], df[col])\n",
    "        plt.title(col)\n",
    "        plt.xlabel(\"epoch\"); plt.ylabel(col)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"KhÃ´ng tÃ¬m tháº¥y\", csv_path)\n",
    "\n",
    "# Ultralytics cÅ©ng Ä‘Ã£ render sáºµn 1 áº£nh tá»•ng há»£p\n",
    "if png_path.exists():\n",
    "    display(IPyImage(filename=str(png_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8f4492-1acc-4177-adc4-e05149e77225",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-28T06:01:42.526210Z",
     "iopub.status.idle": "2025-09-28T06:01:42.526459Z",
     "shell.execute_reply": "2025-09-28T06:01:42.526343Z",
     "shell.execute_reply.started": "2025-09-28T06:01:42.526332Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# 9) VIZ â€” PR / F1 / P / R + Confusion Mat\n",
    "# =========================================\n",
    "from ultralytics import YOLO\n",
    "from IPython.display import display, Image as IPyImage\n",
    "import glob\n",
    "\n",
    "# Äáº£m báº£o Ä‘ang dÃ¹ng best checkpoint\n",
    "model = YOLO(str(best_pt)) if Path(best_pt).exists() else model\n",
    "\n",
    "val_res = model.val(data=DATA_YAML, imgsz=IMG_SIZE, device=0 if torch.cuda.is_available() else \"cpu\", plots=True)\n",
    "val_dir = Path(val_res.save_dir)\n",
    "print(\"Val dir:\", val_dir)\n",
    "\n",
    "# Hiá»ƒn thá»‹ cÃ¡c hÃ¬nh tiÃªu chuáº©n náº¿u cÃ³\n",
    "plot_names = [\n",
    "    \"PR_curve.png\", \"F1_curve.png\", \"P_curve.png\", \"R_curve.png\",\n",
    "    \"confusion_matrix.png\", \"confusion_matrix_normalized.png\", \"results.png\"\n",
    "]\n",
    "for name in plot_names:\n",
    "    p = val_dir / name\n",
    "    if p.exists():\n",
    "        display(IPyImage(filename=str(p)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebdd23d-e8b0-40eb-86c7-52b8aa71a7a5",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-28T06:01:42.527261Z",
     "iopub.status.idle": "2025-09-28T06:01:42.527521Z",
     "shell.execute_reply": "2025-09-28T06:01:42.527410Z",
     "shell.execute_reply.started": "2025-09-28T06:01:42.527392Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# 10) VIZ â€” Sample detections on val set\n",
    "# ======================================\n",
    "from pathlib import Path\n",
    "import random\n",
    "from IPython.display import display, Image as IPyImage\n",
    "\n",
    "val_images = sorted([p for ext in (\"*.png\",\"*.jpg\",\"*.jpeg\") for p in (Path(IMG_VAL)).glob(ext)])\n",
    "sample_paths = random.sample(val_images, k=min(12, len(val_images)))\n",
    "\n",
    "viz_dir = WORKDIR / \"viz_val_samples\"\n",
    "preds = model.predict(\n",
    "    source=[str(p) for p in sample_paths],\n",
    "    imgsz=IMG_SIZE,\n",
    "    conf=float(os.environ.get(\"AICITY_CONF\", \"0.25\")),\n",
    "    iou=float(os.environ.get(\"AICITY_NMS\", \"0.7\")),\n",
    "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
    "    save=True, project=str(viz_dir), name=\"pred\", exist_ok=True, verbose=False\n",
    ")\n",
    "\n",
    "# Hiá»ƒn thá»‹ má»™t vÃ i áº£nh káº¿t quáº£\n",
    "pred_dir = viz_dir / \"pred\"\n",
    "for img_path in sorted(pred_dir.glob(\"*\"))[:12]:\n",
    "    display(IPyImage(filename=str(img_path)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db204aa1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Notes\n",
    "- The leaderboard will evaluate **F1** with hidden GT. This notebook only reports **FPS** and **NormFPS** as described:  \n",
    "  \\[NormFPS = min(FPS, 25) / 25\\].  \n",
    "- You can tune `AICITY_*` env vars for quick experiments:\n",
    "  - `AICITY_MODEL` = `yolo11n.pt|yolo11s.pt|yolo11m.pt|yolo11l.pt|yolo11x.pt`\n",
    "  - `AICITY_EPOCHS` (default 20)\n",
    "  - `AICITY_BATCH`  (default 16)\n",
    "  - `AICITY_IMSIZE` (default 960)\n",
    "  - `AICITY_CONF`   (default 0.25)\n",
    "  - `AICITY_NMS`    (default 0.7)\n",
    "  - `AICITY_MAXDETS` (default 300)\n",
    "\n",
    "**Submission file** to upload: `/kaggle/working/aicity2025_track4/submission.json`\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4405663,
     "sourceId": 7567418,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8312860,
     "sourceId": 13124659,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 511.2628,
   "end_time": "2025-10-13T16:41:27.158443",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-13T16:32:55.895643",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
